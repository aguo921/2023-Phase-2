{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA 2023 Phase 2 - Run Training Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and connect to workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.52.0 to work with MSA-Phase2-Azure\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a parameterised training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training\\\\market_segmentation.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('../1. Analysis and Preprocessing/preprocessed_datasets/market_segmentation.csv', os.path.join(training_folder, \"market_segmentation.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/training.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "# load the market segmentation dataset\n",
    "print(\"Loading Data...\")\n",
    "market_segmentation = pd.read_csv('market_segmentation.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = market_segmentation.drop(columns=\"Segmentation\"), market_segmentation.Segmentation\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "for class_of_interest in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "    auc = roc_auc_score(y_onehot_test[:,class_id],y_scores[:,class_id])\n",
    "    print(f'AUC {class_of_interest} vs rest: ' + str(auc))\n",
    "    run.log(f'AUC {class_of_interest} vs rest', np.float(auc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"aguo921\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the script with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'train-segmentation_1690711593_de16741d',\n",
       " 'target': 'aguo921',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2023-07-30T10:17:12.778654Z',\n",
       " 'endTimeUtc': '2023-07-30T10:18:29.353115Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcdsi',\n",
       "  'ContentSnapshotId': '72625ca4-dbfe-429e-b555-77db63b1093c',\n",
       "  'azureml.git.repository_uri': 'https://github.com/aguo921/2023-Phase-2.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/aguo921/2023-Phase-2.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '925700ddc7dfe061c2b5ae022e1171975d4bbea9',\n",
       "  'mlflow.source.git.commit': '925700ddc7dfe061c2b5ae022e1171975d4bbea9',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--reg_rate', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'aguo921',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': 'Autosave_2023-07-30T10:06:37Z_02ee97e4',\n",
       "   'assetId': 'azureml://locations/australiaeast/workspaces/cda9c533-b966-40a6-a49f-925903601854/environments/experiment_env/versions/Autosave_2023-07-30T10:06:37Z_02ee97e4',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'simple_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults', 'azureml-mlflow']}]},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230620.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=lorAwOsa35MJqEKt7scYCFU2%2FtMnHGqN2zaXRLvVdDg%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A08%3A16Z&se=2023-07-30T18%3A18%3A16Z&sp=r',\n",
       "  'user_logs/std_log.txt': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=%2FOmKWPblVG6KkLRpvfMVRhxFQHj7u2CWhkRsxiNJIhA%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=qU%2BqyaWwQBkVDHwp2MvbjPepWiWKfOWfjrCqQN%2Bkxfc%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=taNOR25x0rt8x3fHWTIJEWKOKQDTmphc6tPE%2FUrvPS4%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=Fuxn4R7ToahbZKAEICTzkWE4VG%2FgRA%2BxrHDNKp%2FLO3Y%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=5x98%2Fa6X6scDv%2FdeMOOfHRDxjYrCcl%2FQsTpXKun5hDg%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r',\n",
       "  'system_logs/lifecycler/vm-bootstrapper.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/system_logs/lifecycler/vm-bootstrapper.log?sv=2019-07-07&sr=b&sig=W7byFbs1sTNkvyPo0%2BGBWJR4QJUGNAnl7AUfkpPjlOc%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r',\n",
       "  'system_logs/metrics_capability/metrics-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=OIEkuE%2FKXCp3JhJgH0A5nr0Jxw4wfeL%2BVjgUwYGWq8E%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r',\n",
       "  'system_logs/snapshot_capability/snapshot-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation_1690711593_de16741d/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=dtbOnmzbZ2UxEoAxVgOOWqH3lqmxAnewmmwsyoTCPEY%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-07-30T08%3A19%3A44Z&ske=2023-07-31T16%3A29%3A44Z&sks=b&skv=2019-07-07&st=2023-07-30T10%3A09%3A22Z&se=2023-07-30T18%3A19%3A22Z&sp=r'},\n",
       " 'submittedBy': 'Angela Guo'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", \"training/environment.yaml\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=training_folder,\n",
    "                                script='training.py',\n",
    "                                arguments = ['--reg_rate', 0.1],\n",
    "                                environment=env,\n",
    "                                docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "                                compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment run\n",
    "experiment_name = 'train-segmentation'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Rate : 0.01\n",
      "Accuracy : 0.4900296987696224\n",
      "AUC A vs rest : 0.7113390862280469\n",
      "AUC B vs rest : 0.6641015473983684\n",
      "AUC C vs rest : 0.754124484439445\n",
      "AUC D vs rest : 0.8668678371578138\n",
      "\n",
      "\n",
      "azureml-logs/20_image_build_log.txt\n",
      "outputs/model.pkl\n",
      "system_logs/cs_capability/cs-capability.log\n",
      "system_logs/hosttools_capability/hosttools-capability.log\n",
      "system_logs/lifecycler/execution-wrapper.log\n",
      "system_logs/lifecycler/lifecycler.log\n",
      "system_logs/lifecycler/vm-bootstrapper.log\n",
      "system_logs/metrics_capability/metrics-capability.log\n",
      "system_logs/snapshot_capability/snapshot-capability.log\n",
      "user_logs/std_log.txt\n"
     ]
    }
   ],
   "source": [
    "# Get logged metrics and files\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, \":\", metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation-model version: 2\n",
      "\t Training context : Script\n",
      "\t AUC A vs rest : 0.7113390862280469\n",
      "\t AUC B vs rest : 0.6641015473983684\n",
      "\t AUC C vs rest : 0.754124484439445\n",
      "\t AUC D vs rest : 0.8668678371578138\n",
      "\t Accuracy : 0.4900296987696224\n",
      "\n",
      "\n",
      "segmentation-model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC A vs rest : 0.7113390862280469\n",
      "\t AUC B vs rest : 0.6641015473983684\n",
      "\t AUC C vs rest : 0.754124484439445\n",
      "\t AUC D vs rest : 0.8668678371578138\n",
      "\t Accuracy : 0.4900296987696224\n",
      "\n",
      "\n",
      "segmentation-logistic-regression version: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/model.pkl', model_name='segmentation-model',\n",
    "                   tags={'Training context':'Script'},\n",
    "                   properties={\n",
    "                    'AUC A vs rest': run.get_metrics()['AUC A vs rest'],\n",
    "                    'AUC B vs rest': run.get_metrics()['AUC B vs rest'],\n",
    "                    'AUC C vs rest': run.get_metrics()['AUC C vs rest'],\n",
    "                    'AUC D vs rest': run.get_metrics()['AUC D vs rest'],\n",
    "                    'Accuracy': run.get_metrics()['Accuracy']\n",
    "                    })\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
