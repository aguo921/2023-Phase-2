{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA 2023 Phase 2 - Run Training Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and connect to workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.52.0 to work with MSA-Phase2-Azure\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a parameterised training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training\\\\market_segmentation.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy(\n",
    "    '../1. Analysis and Preprocessing/preprocessed_datasets/market_segmentation_interaction.csv',\n",
    "    os.path.join(training_folder, \"market_segmentation_interaction.csv\")\n",
    ")\n",
    "shutil.copy(\n",
    "    '../1. Analysis and Preprocessing/preprocessed_datasets/market_segmentation.csv',\n",
    "    os.path.join(training_folder, \"market_segmentation.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/lg-training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/lg-training.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "# load the market segmentation dataset\n",
    "print(\"Loading Data...\")\n",
    "market_segmentation = pd.read_csv('market_segmentation_interaction.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = market_segmentation.drop(columns=\"Segmentation\"), market_segmentation.Segmentation\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg).fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "for class_of_interest in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "    auc = roc_auc_score(y_onehot_test[:,class_id],y_scores[:,class_id])\n",
    "    print(f'AUC {class_of_interest} vs rest: ' + str(auc))\n",
    "    run.log(f'AUC {class_of_interest} vs rest', np.float(auc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/lg-model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training/rf-training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/rf-training.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set hyperparameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--max_features', type=int, dest='max_features', default=4)\n",
    "parser.add_argument('--max_depth', type=int, dest='max_depth', default=None)\n",
    "parser.add_argument('--min_samples_split', type=int, dest='min_samples_split', default=2)\n",
    "parser.add_argument('--min_samples_leaf', type=int, dest='min_samples_leaf', default=1)\n",
    "args = parser.parse_args()\n",
    "max_features = args.max_features\n",
    "max_depth = args.max_depth\n",
    "min_samples_split = args.min_samples_split\n",
    "min_samples_leaf = args.min_samples_leaf\n",
    "\n",
    "# load the market segmentation dataset\n",
    "print(\"Loading Data...\")\n",
    "market_segmentation = pd.read_csv('market_segmentation.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = market_segmentation.drop(columns=\"Segmentation\"), market_segmentation.Segmentation\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a random forest model\n",
    "print(\n",
    "    'Training a random forest model with max features of', max_features,\n",
    "    'max depth of', max_depth,\n",
    "    'min samples split of', min_samples_split,\n",
    "    'and min_samples_leaf of', min_samples_leaf\n",
    ")\n",
    "run.log('Maximum depth of tree', max_depth)\n",
    "run.log('Maximum features per split', max_features)\n",
    "run.log('Minimum samples requierd for split', min_samples_split)\n",
    "run.log('Minimum samples per leaf', min_samples_leaf)\n",
    "model = RandomForestClassifier(\n",
    "    max_features=max_features,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "for class_of_interest in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "    auc = roc_auc_score(y_onehot_test[:,class_id],y_scores[:,class_id])\n",
    "    print(f'AUC {class_of_interest} vs rest: ' + str(auc))\n",
    "    run.log(f'AUC {class_of_interest} vs rest', np.float(auc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/rf-model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"aguo921\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the script with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/environment.yml\n",
    "name: batch_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- numpy\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'train-segmentation-lg_1690932545_36eca8b1',\n",
       " 'target': 'aguo921',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2023-08-01T23:29:19.464458Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcdsi',\n",
       "  'ContentSnapshotId': 'f2af527f-0515-42d8-8110-28527c2c6b32',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json',\n",
       "  'azureml.git.repository_uri': 'https://github.com/aguo921/2023-Phase-2.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/aguo921/2023-Phase-2.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '7713ca5b70f1a9b878d98a95edff6282e85729c0',\n",
       "  'mlflow.source.git.commit': '7713ca5b70f1a9b878d98a95edff6282e85729c0',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'lg-training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--reg_rate', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'aguo921',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': 'Autosave_2023-07-31T21:15:37Z_454ee9d3',\n",
       "   'assetId': 'azureml://locations/australiaeast/workspaces/cda9c533-b966-40a6-a49f-925903601854/environments/experiment_env/versions/Autosave_2023-07-31T21:15:37Z_454ee9d3',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'batch_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'numpy',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults']}]},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230620.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'user_logs/std_log.txt': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=Fa1ul0rkDROF2HzGeUOckCSUDgF7IitECgm%2B2YcMw9k%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A19%3A20Z&ske=2023-08-03T07%3A29%3A20Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=4Mmw35%2BUN9X3pHkoakcajjNG07NoeQtPpR1Kc%2FJGFNM%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T22%3A16%3A46Z&ske=2023-08-03T06%3A26%3A46Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=aJzGXlu3vP9GhGWiRRlJBu938L2NYyR5mIiYW%2F5U1Gw%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T22%3A16%3A46Z&ske=2023-08-03T06%3A26%3A46Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=fZnzvWFPBgmS%2BtUji%2BqGQvofcZfIwCaLKkQR4P7EiFI%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T22%3A16%3A46Z&ske=2023-08-03T06%3A26%3A46Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=MbJDlXopcaqeseP5ocicwle%2Fga7AtLb16TpI7qa%2F8mM%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T22%3A16%3A46Z&ske=2023-08-03T06%3A26%3A46Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r',\n",
       "  'system_logs/lifecycler/vm-bootstrapper.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/system_logs/lifecycler/vm-bootstrapper.log?sv=2019-07-07&sr=b&sig=8%2BdgGgrj%2BgK1f7MPp213ZVW6%2B7%2FH7NEAmRrS3rCZgtY%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T22%3A16%3A46Z&ske=2023-08-03T06%3A26%3A46Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r',\n",
       "  'system_logs/metrics_capability/metrics-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=S6MblgQTSqFEd4aSVUdC0iiwctHRIpBPbrWScond4jc%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T22%3A16%3A46Z&ske=2023-08-03T06%3A26%3A46Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r',\n",
       "  'system_logs/snapshot_capability/snapshot-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-lg_1690932545_36eca8b1/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=vAUtMA90FVYpad1FVXvr3FHmix4ciOUI5EQ4Wlel9AM%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T22%3A16%3A46Z&ske=2023-08-03T06%3A26%3A46Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A19%3A31Z&se=2023-08-02T07%3A29%3A31Z&sp=r'},\n",
       " 'submittedBy': 'Angela Guo'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", training_folder + \"/environment.yml\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(\n",
    "    source_directory=training_folder,\n",
    "    script='lg-training.py',\n",
    "    arguments = ['--reg_rate', 0.1],\n",
    "    environment=env,\n",
    "    docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "    compute_target=cluster_name\n",
    ") \n",
    "\n",
    "# submit the experiment run\n",
    "experiment_name = 'train-segmentation-lg'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run_lg = experiment.submit(config=script_config)\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run_lg.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'train-segmentation-rf_1690932661_3eb821b7',\n",
       " 'target': 'aguo921',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2023-08-01T23:31:09.796301Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcdsi',\n",
       "  'ContentSnapshotId': 'f2af527f-0515-42d8-8110-28527c2c6b32',\n",
       "  'azureml.git.repository_uri': 'https://github.com/aguo921/2023-Phase-2.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/aguo921/2023-Phase-2.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '7713ca5b70f1a9b878d98a95edff6282e85729c0',\n",
       "  'mlflow.source.git.commit': '7713ca5b70f1a9b878d98a95edff6282e85729c0',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'rf-training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--max_depth',\n",
       "   '50',\n",
       "   '--max_features',\n",
       "   '5',\n",
       "   '--min_samples_split',\n",
       "   '4',\n",
       "   '--min_samples_leaf',\n",
       "   '4'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'aguo921',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': 'Autosave_2023-07-31T21:15:37Z_454ee9d3',\n",
       "   'assetId': 'azureml://locations/australiaeast/workspaces/cda9c533-b966-40a6-a49f-925903601854/environments/experiment_env/versions/Autosave_2023-07-31T21:15:37Z_454ee9d3',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'batch_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'numpy',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults']}]},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230620.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'user_logs/std_log.txt': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=DNvOMi8ImjjAvgH%2BQgdEYUAXsx5JP3foU8V%2BZYBwl50%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T21%3A49%3A51Z&ske=2023-08-03T05%3A59%3A51Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=AHVTR6vDLjfFE%2Bzf0ud3JQ1siYPkk3KrERemnFX0rno%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A14%3A27Z&ske=2023-08-03T07%3A24%3A27Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=0SNj6fN3pHWdpx4U1RiBmiUzLo5L8i8%2F8YrjoDaVWOw%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A14%3A27Z&ske=2023-08-03T07%3A24%3A27Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=NwJFY%2FcuAcUWTjrOOTXXCSzMJqjmGWg%2B%2FESMZhnYhNo%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A14%3A27Z&ske=2023-08-03T07%3A24%3A27Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=YuNjYWCAscSlixfZoSVhzp8l96RBRaai7h9yemHMK2w%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A14%3A27Z&ske=2023-08-03T07%3A24%3A27Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r',\n",
       "  'system_logs/lifecycler/vm-bootstrapper.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/system_logs/lifecycler/vm-bootstrapper.log?sv=2019-07-07&sr=b&sig=iWMisCyqzAQE5xkFyleAEWuo%2FwNet%2FnYW2CJap1DDpA%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A14%3A27Z&ske=2023-08-03T07%3A24%3A27Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r',\n",
       "  'system_logs/metrics_capability/metrics-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=0Zso3VfSs0HDimXdaW84OcLWj60WcYb2AZ2MyiUZpRQ%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A14%3A27Z&ske=2023-08-03T07%3A24%3A27Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r',\n",
       "  'system_logs/snapshot_capability/snapshot-capability.log': 'https://msaphase2azure3140485650.blob.core.windows.net/azureml/ExperimentRun/dcid.train-segmentation-rf_1690932661_3eb821b7/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=5GxxCdIJuHQJpL6MpWPjT%2FUYb0nAZaZQz29Gzc28WSo%3D&skoid=03ad897f-d537-417d-a9db-3ae152a154f2&sktid=d1b36e95-0d50-42e9-958f-b63fa906beaa&skt=2023-08-01T23%3A14%3A27Z&ske=2023-08-03T07%3A24%3A27Z&sks=b&skv=2019-07-07&st=2023-08-01T23%3A21%3A22Z&se=2023-08-02T07%3A31%3A22Z&sp=r'},\n",
       " 'submittedBy': 'Angela Guo'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", training_folder + \"/environment.yml\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(\n",
    "    source_directory=training_folder,\n",
    "    script='rf-training.py',\n",
    "    arguments = ['--max_depth', 50, '--max_features', 5, '--min_samples_split', 4, '--min_samples_leaf', 4],\n",
    "    environment=env,\n",
    "    docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "    compute_target=cluster_name\n",
    ") \n",
    "\n",
    "# submit the experiment run\n",
    "experiment_name = 'train-segmentation-rf'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run_rf = experiment.submit(config=script_config)\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run_rf.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Rate : 0.1\n",
      "Accuracy : 0.4965453707968678\n",
      "AUC A vs rest : 0.6942899716985923\n",
      "AUC C vs rest : 0.7599926507739654\n",
      "AUC B vs rest : 0.6838742009488384\n",
      "AUC D vs rest : 0.8749635705529935\n",
      "\n",
      "\n",
      "outputs/lg-model.pkl\n",
      "system_logs/cs_capability/cs-capability.log\n",
      "system_logs/hosttools_capability/hosttools-capability.log\n",
      "system_logs/lifecycler/execution-wrapper.log\n",
      "system_logs/lifecycler/lifecycler.log\n",
      "system_logs/lifecycler/vm-bootstrapper.log\n",
      "system_logs/metrics_capability/metrics-capability.log\n",
      "system_logs/snapshot_capability/snapshot-capability.log\n",
      "user_logs/std_log.txt\n"
     ]
    }
   ],
   "source": [
    "# Get logged metrics and files for logistic regression training\n",
    "metrics = run_lg.get_metrics()\n",
    "for key in metrics.keys():\n",
    "    print(key, \":\", metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run_lg.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum depth of tree : 50\n",
      "Maximum features per split : 5\n",
      "Minimum samples requierd for split : 4\n",
      "Minimum samples per leaf : 4\n",
      "Accuracy : 0.49746660525103636\n",
      "AUC A vs rest : 0.7171151955013227\n",
      "AUC B vs rest : 0.6807604071541529\n",
      "AUC C vs rest : 0.7722985852739883\n",
      "AUC D vs rest : 0.8757733610085896\n",
      "\n",
      "\n",
      "outputs/rf-model.pkl\n",
      "system_logs/cs_capability/cs-capability.log\n",
      "system_logs/hosttools_capability/hosttools-capability.log\n",
      "system_logs/lifecycler/execution-wrapper.log\n",
      "system_logs/lifecycler/lifecycler.log\n",
      "system_logs/lifecycler/vm-bootstrapper.log\n",
      "system_logs/metrics_capability/metrics-capability.log\n",
      "system_logs/snapshot_capability/snapshot-capability.log\n",
      "user_logs/std_log.txt\n"
     ]
    }
   ],
   "source": [
    "# Get logged metrics and files for random forest training\n",
    "metrics = run_rf.get_metrics()\n",
    "for key in metrics.keys():\n",
    "    print(key, \":\", metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run_rf.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='MSA-Phase2-Azure', subscription_id='b5ba4903-ea86-4021-ae33-60b2d6e5d120', resource_group='MSA-Phase2-Azure'), name=segmentation-lg, id=segmentation-lg:2, version=2, tags={'Training context': 'Script'}, properties={'AUC A vs rest': '0.6942899716985923', 'AUC B vs rest': '0.6838742009488384', 'AUC C vs rest': '0.7599926507739654', 'AUC D vs rest': '0.8749635705529935', 'Accuracy': '0.4965453707968678'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the logistic regression model\n",
    "run_lg.register_model(\n",
    "    model_path='outputs/lg-model.pkl', model_name='segmentation-lg',\n",
    "    tags={'Training context':'Script'},\n",
    "    properties={\n",
    "        'AUC A vs rest': run_lg.get_metrics()['AUC A vs rest'],\n",
    "        'AUC B vs rest': run_lg.get_metrics()['AUC B vs rest'],\n",
    "        'AUC C vs rest': run_lg.get_metrics()['AUC C vs rest'],\n",
    "        'AUC D vs rest': run_lg.get_metrics()['AUC D vs rest'],\n",
    "        'Accuracy': run_lg.get_metrics()['Accuracy']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='MSA-Phase2-Azure', subscription_id='b5ba4903-ea86-4021-ae33-60b2d6e5d120', resource_group='MSA-Phase2-Azure'), name=segmentation-rf, id=segmentation-rf:1, version=1, tags={'Training context': 'Script'}, properties={'AUC A vs rest': '0.7171151955013227', 'AUC B vs rest': '0.6807604071541529', 'AUC C vs rest': '0.7722985852739883', 'AUC D vs rest': '0.8757733610085896', 'Accuracy': '0.49746660525103636'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the random forest model\n",
    "run_rf.register_model(\n",
    "    model_path='outputs/rf-model.pkl', model_name='segmentation-rf',\n",
    "    tags={'Training context':'Script'},\n",
    "    properties={\n",
    "        'AUC A vs rest': run_rf.get_metrics()['AUC A vs rest'],\n",
    "        'AUC B vs rest': run_rf.get_metrics()['AUC B vs rest'],\n",
    "        'AUC C vs rest': run_rf.get_metrics()['AUC C vs rest'],\n",
    "        'AUC D vs rest': run_rf.get_metrics()['AUC D vs rest'],\n",
    "        'Accuracy': run_rf.get_metrics()['Accuracy']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation-rf version: 1\n",
      "\t Training context : Script\n",
      "\t AUC A vs rest : 0.7171151955013227\n",
      "\t AUC B vs rest : 0.6807604071541529\n",
      "\t AUC C vs rest : 0.7722985852739883\n",
      "\t AUC D vs rest : 0.8757733610085896\n",
      "\t Accuracy : 0.49746660525103636\n",
      "\n",
      "\n",
      "segmentation-lg version: 2\n",
      "\t Training context : Script\n",
      "\t AUC A vs rest : 0.6942899716985923\n",
      "\t AUC B vs rest : 0.6838742009488384\n",
      "\t AUC C vs rest : 0.7599926507739654\n",
      "\t AUC D vs rest : 0.8749635705529935\n",
      "\t Accuracy : 0.4965453707968678\n",
      "\n",
      "\n",
      "segmentation-lg version: 1\n",
      "\t Training context : Script\n",
      "\t AUC A vs rest : 0.6942899716985923\n",
      "\t AUC B vs rest : 0.6838742009488384\n",
      "\t AUC C vs rest : 0.7599926507739654\n",
      "\t AUC D vs rest : 0.8749635705529935\n",
      "\t Accuracy : 0.4965453707968678\n",
      "\n",
      "\n",
      "segmentation-logistic-regression version: 4\n",
      "\n",
      "\n",
      "segmentation-logistic-regression version: 3\n",
      "\n",
      "\n",
      "segmentation-model version: 5\n",
      "\t Training context : Hyperdrive\n",
      "\t AUC A vs rest : 0.7173467464996174\n",
      "\t AUC B vs rest : 0.6771250706291696\n",
      "\t AUC C vs rest : 0.7548471920284576\n",
      "\t AUC D vs rest : 0.8663999845277084\n",
      "\t Accuracy : 0.4968179889690284\n",
      "\n",
      "\n",
      "segmentation-model version: 4\n",
      "\t Training context : Hyperdrive\n",
      "\t AUC A vs rest : 0.7173467464996174\n",
      "\t AUC B vs rest : 0.6771250706291696\n",
      "\t AUC C vs rest : 0.7548471920284576\n",
      "\t AUC D vs rest : 0.8663999845277084\n",
      "\t Accuracy : 0.4968179889690284\n",
      "\n",
      "\n",
      "segmentation-model version: 3\n",
      "\t Training context : Hyperdrive\n",
      "\t AUC A vs rest : 0.7111122006745038\n",
      "\t AUC B vs rest : 0.6643216130215407\n",
      "\t AUC C vs rest : 0.7541089423407565\n",
      "\t AUC D vs rest : 0.8669461195860793\n",
      "\t Accuracy : 0.49087823504454814\n",
      "\n",
      "\n",
      "segmentation-logistic-regression version: 2\n",
      "\n",
      "\n",
      "segmentation-model version: 2\n",
      "\t Training context : Script\n",
      "\t AUC A vs rest : 0.7113390862280469\n",
      "\t AUC B vs rest : 0.6641015473983684\n",
      "\t AUC C vs rest : 0.754124484439445\n",
      "\t AUC D vs rest : 0.8668678371578138\n",
      "\t Accuracy : 0.4900296987696224\n",
      "\n",
      "\n",
      "segmentation-model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC A vs rest : 0.7113390862280469\n",
      "\t AUC B vs rest : 0.6641015473983684\n",
      "\t AUC C vs rest : 0.754124484439445\n",
      "\t AUC D vs rest : 0.8668678371578138\n",
      "\t Accuracy : 0.4900296987696224\n",
      "\n",
      "\n",
      "segmentation-logistic-regression version: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
